{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4069e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: cellsnp output with unwanted cols removed\n",
    "# part 1: create defaultdict with d[barcode_index]((position, count)); output the dict\n",
    "# part 2: reduce dict with duplicate vals (barcode multiplets)\n",
    "# to contain only the keys with unique values; output the cleaned dict\n",
    "# if barcode_indices have identical 1) and 2) then they are considered barcode multiplets and removed\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_dict(in_file):\n",
    "    # create dict of sets for each barcode_id\n",
    "    d = defaultdict(set)\n",
    "    \n",
    "    with open(in_file, 'r') as f:\n",
    "        # skip first three rows\n",
    "        next(f)\n",
    "        next(f)\n",
    "        next(f)\n",
    "        \n",
    "        # format of in_file\n",
    "        # 1 29195 1\n",
    "        # 1 93378 2\n",
    "        # position_id \\t barcode_id \\t count \\n\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip('\\n').split('\\t')\n",
    "            # add (position_id,count) to each barcode_id\n",
    "            # using a set means no (position_id,count) duplicates will be added to the same barcode\n",
    "            d[line[1]].add((line[0], int(line[2])))\n",
    "    \n",
    "    f.close()\n",
    "    print(f'Number of cells before dup and zero removal: {len(d)}')\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "# remove duplicates based on 1) marker positions and 2) per marker position mapping counts\n",
    "\n",
    "def remove_duplicates_and_zeros(d):\n",
    "    # empty duplicates and retain unique\n",
    "    count_dup = 0#\n",
    "    for i,value in enumerate(d.values()):\n",
    "        # search for (position_id,count) duplicates between barcodes\n",
    "        # if counted more than one pair between barcodes\n",
    "        if list(d.values()).count(value) > 1:\n",
    "            # update counter\n",
    "            count_dup += 1\n",
    "            # remove the content of the current barcode and preserve the content of the other barcode(s)\n",
    "            # this will remove the content of all barcodes with duplicate contents, until one remain\n",
    "            d[list(d.keys())[i]] = ()\n",
    "    \n",
    "    # how many cells had multiple barcodes?\n",
    "    print(f'Number of duplicate keys: {count_dup}')#\n",
    "    \n",
    "    \n",
    "    # create tuple to contain barcodes with no content\n",
    "    # either due to no content or removal in prev step\n",
    "    zero_keys = ()\n",
    "    for i,value in enumerate(d.values()):\n",
    "        # if a key's value is empty, add key to the tuple\n",
    "        # the only way to grab key from evaluating value is by enumerating the keys/values\n",
    "        if not value:\n",
    "            zero_keys += (list(d.keys())[i],)\n",
    "            \n",
    "    print(f'Number of zero keys after emptying duplicates: {len(zero_keys)}')#\n",
    "    \n",
    "    # rm zero_keys from output dict\n",
    "    for key in zero_keys:\n",
    "        d.pop(key)\n",
    "    \n",
    "    print(f'Number of cells after dup and zero removal: {len(d)}')#\n",
    "    \n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45ddad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells before dup and zero removal: 387366\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kv/hmgc8p8d15506b39v58xj47h0000gn/T/ipykernel_10392/2988163308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicates_and_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mavgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/shell/MSc/LMU/Schneeberger/out/{}_avgs1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kv/hmgc8p8d15506b39v58xj47h0000gn/T/ipykernel_10392/1720634865.py\u001b[0m in \u001b[0;36mremove_duplicates_and_zeros\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# input: cellsnp output with unwanted cols removed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# part 1: create defaultdict with d[barcode_index]((position, count)); output the dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# part 2: reduce dict with duplicate vals (barcode multiplets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# to contain only the keys with unique values; output the cleaned dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run on real dataset\n",
    "\n",
    "#for X in ('A','B','C'):\n",
    "for X in ('B'):\n",
    "    \n",
    "    in_file = '/Users/shell/MSc/LMU/Schneeberger/data/{}/cellSNP.tag.DP.mtx'.format(X)\n",
    "    \n",
    "    d = create_dict(in_file)\n",
    "    avgs = [(int(key), sum([tup[1] for tup in d[key]])/len(d[key])) for key in d]\n",
    "    # I think I could just use sum(d.values())/len(d.values())\n",
    "    # oh, but this requires the dict value to be an int, whereas it is a tup now\n",
    "    with open('/Users/shell/MSc/LMU/Schneeberger/out/{}_avgs0.csv'.format(X), 'w+') as fw:\n",
    "        for pair in avgs:\n",
    "            fw.write(f'{pair[0]},{pair[1]}\\n')\n",
    "    \n",
    "    # remove\n",
    "    d = remove_duplicates_and_zeros(d)\n",
    "    avgs = [(int(key), sum([tup[1] for tup in d[key]])/len(d[key])) for key in d]\n",
    "    with open('/Users/shell/MSc/LMU/Schneeberger/out/{}_avgs1.csv'.format(X), 'w+') as fw:\n",
    "        for pair in avgs:\n",
    "            fw.write(f'{pair[0]},{pair[1]}\\n')\n",
    "            \n",
    "    print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bdc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number of cells before dup and zero removal: 273273\n",
    "Number of duplicate keys: 20481\n",
    "Number of zero keys after emptying duplicates: 20481\n",
    "Number of cells after dup and zero removal: 252792\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf53f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells before dup and zero removal: 1013\n",
      "Number of duplicate keys: 578\n",
      "Number of zero keys after emptying duplicates: 578\n",
      "Number of cells after dup and zero removal: 435\n"
     ]
    }
   ],
   "source": [
    "# run on test dataset: small\n",
    "\n",
    "in_file = '/Users/shell/MSc/LMU/Schneeberger/cellSNP_small.mtx'\n",
    "d = create_dict(in_file)\n",
    "avgs = [(int(key), sum([tup[1] for tup in d[key]])/len(d[key])) for key in d]\n",
    "with open('/Users/shell/MSc/LMU/Schneeberger/small_avgs0.csv', 'w+') as fw:\n",
    "    fw.write('barcode_index,avg_count\\n')\n",
    "    for pair in avgs:\n",
    "        fw.write(f'{pair[0]},{round(pair[1],2)}\\n')\n",
    "\n",
    "# remove\n",
    "d = remove_duplicates_and_zeros(d)\n",
    "\n",
    "avgs = [(int(key), sum([tup[1] for tup in d[key]])/len(d[key])) for key in d]\n",
    "with open('/Users/shell/MSc/LMU/Schneeberger/small_avgs1.csv', 'w+') as fw:\n",
    "    fw.write('barcode_index,avg_count\\n')\n",
    "    for pair in avgs:\n",
    "        fw.write(f'{pair[0]},{round(pair[1],2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d90d81d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells before dup and zero removal: 4\n",
      "Number of duplicate keys: 1\n",
      "Number of zero keys after emptying duplicates: 1\n",
      "Number of cells after dup and zero removal: 3\n"
     ]
    }
   ],
   "source": [
    "# run on test dataset: tiny\n",
    "\n",
    "in_file = '/Users/shell/MSc/LMU/Schneeberger/tiny_cellsnp.mtx'\n",
    "d = create_dict(in_file)\n",
    "# for each key in d\n",
    "# add tuple to list\n",
    "# 1st element is int(key): barcode_index as int\n",
    "# 2nd element is sum([tup[1] for tup in d[key]])/len(d[key]): avg read count per barcode\n",
    "avgs = [(int(key), sum([tup[1] for tup in d[key]])/len(d[key])) for key in d]\n",
    "with open('/Users/shell/MSc/LMU/Schneeberger/tiny_avgs0.csv', 'w+') as fw:\n",
    "    fw.write('barcode_index,avg_count\\n')\n",
    "    for pair in avgs:\n",
    "        fw.write(f'{pair[0]},{round(pair[1],2)}\\n')\n",
    "\n",
    "# remove\n",
    "d = remove_duplicates_and_zeros(d)\n",
    "\n",
    "avgs = [(int(key), sum([tup[1] for tup in d[key]])/len(d[key])) for key in d]\n",
    "with open('/Users/shell/MSc/LMU/Schneeberger/tiny_avgs1.csv', 'w+') as fw:\n",
    "    fw.write('barcode_index,avg_count\\n')\n",
    "    for pair in avgs:\n",
    "        fw.write(f'{pair[0]},{round(pair[1],2)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0a18c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'29196': {('1', 1), ('2', 1)},\n",
       "             '29198': {('1', 1), ('1', 2)},\n",
       "             '15533': {('1', 1)}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "243aa0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.5\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for pair in avgs:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/dss/dsshome1/08/ra65mav/.conda/envs/py3.11/bin/python\n",
    "'''\n",
    "This script generates avg depth with and without removal of barcode multiplets\n",
    "# input: unmodified cellsnp output\n",
    "# part 1: create defaultdict with d[barcode_index]((position, count)); output the dict\n",
    "# part 2: reduce dict with duplicate vals (barcode multiplets)\n",
    "# part 3: write avg depth per barcode_index, write to file\n",
    "# to contain only the keys with unique values; output the cleaned dict\n",
    "'''\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# sys.argv[0] is the name of the python script\n",
    "cellsnp_file_path = sys.argv[1]\n",
    "output1_file_path = sys.argv[2]\n",
    "output2_file_path = sys.argv[3]\n",
    "\n",
    "# Example file paths\n",
    "# cellsnp_file_path = '/dss/dsslegfs01/pn29fi/pn29fi-dss-0008/Yuying/cellsnp_lite_results/B_nigra_paternal_5733_B/cellSNP.tag.DP.mtx'\n",
    "# output1_file_path = '/dss/dsslegfs01/pn29fi/pn29fi-dss-0008/Yuying/out/B_avgs.csv'\n",
    "# output2_file_path = '/dss/dsslegfs01/pn29fi/pn29fi-dss-0008/Yuying/out/B_avgs_dup_rm.csv'\n",
    "\n",
    "print(f\"cellsnp_file_path = '{cellsnp_file_path}';\")\n",
    "print(f\"output1_file_path (all cells) = '{output1_file_path}';\")\n",
    "print(f\"output2_file_path (after barcode multiplet removal) = '{output2_file_path}'.\")\n",
    "\n",
    "\n",
    "\n",
    "def create_dict(in_file):\n",
    "    # create dict of sets for each barcode_id\n",
    "    d = defaultdict(set)\n",
    "    \n",
    "    with open(in_file, 'r') as f:\n",
    "        # skip first three rows\n",
    "        next(f)\n",
    "        next(f)\n",
    "        next(f)\n",
    "        # format of in_file: position_id \\t barcode_id \\t count \\n\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip('\\n').split('\\t')\n",
    "            # add (position_id,count) to each barcode_id\n",
    "            # using a set means no (position_id,count) duplicates will be added to the same barcode\n",
    "            d[line[1]].add((line[0], int(line[2])))\n",
    "    \n",
    "    f.close()\n",
    "    print(f'Number of cells before dup and zero removal: {len(d)}')\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "# remove duplicates based on 1) marker positions and 2) per marker position mapping counts\n",
    "# if barcode_indices have identical 1) and 2) then they are considered barcode multiplets and removed\n",
    "\n",
    "def remove_duplicates_and_zeros(d):\n",
    "    # empty duplicates and retain unique\n",
    "    count_dup = 0#\n",
    "    for i,value in enumerate(d.values()):\n",
    "        # search for (position_id,count) duplicates between barcodes\n",
    "        # if counted more than one pair between barcodes\n",
    "        if list(d.values()).count(value) > 1:\n",
    "            # update counter\n",
    "            count_dup += 1\n",
    "            # remove the content of the current barcode and preserve the content of the other barcode(s)\n",
    "            # this will remove the content of all barcodes with duplicate contents, until one remain\n",
    "            d[list(d.keys())[i]] = ()\n",
    "    \n",
    "    # how many cells had multiple barcodes?\n",
    "    print(f'Number of duplicate keys: {count_dup}')#\n",
    "    \n",
    "    # create tuple to contain barcodes with no content\n",
    "    # either due to no content or removal in prev step\n",
    "    zero_keys = ()\n",
    "    for i,value in enumerate(d.values()):\n",
    "        # if a key's value is empty, add key to the tuple\n",
    "        # the only way to grab key from evaluating value is by enumerating the keys/values\n",
    "        if not value:\n",
    "            zero_keys += (list(d.keys())[i],)\n",
    "            \n",
    "    print(f'Number of zero keys after emptying duplicates: {len(zero_keys)}')#\n",
    "    \n",
    "    # rm zero_keys from output dict\n",
    "    for key in zero_keys:\n",
    "        d.pop(key)\n",
    "    \n",
    "    print(f'Number of cells after dup and zero removal: {len(d)}')#\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "# write output to file\n",
    "d = create_dict(cellsnp_file_path)\n",
    "avgs = [(int(key), sum([tup[1] for tup in d[key]])/len(d[key])) for key in d]\n",
    "with open(output1_file_path, 'w+') as fw:\n",
    "    fw.write('position_index,avg_depth\\n')\n",
    "    for pair in avgs:\n",
    "        fw.write(f'{pair[0]},{round(pair[1],2)}\\n')\n",
    "print('done 1/2')\n",
    "\n",
    "d = remove_duplicates_and_zeros(d)\n",
    "avgs = [(int(key), sum([tup[1] for tup in d[key]])/len(d[key])) for key in d]\n",
    "with open('/Users/shell/MSc/LMU/Schneeberger/out/{}_avgs1.csv', 'w+') as fw:\n",
    "    fw.write('position_index,avg_depth\\n')\n",
    "    for pair in avgs:\n",
    "        fw.write(f'{pair[0]},{round(pair[1],2)}\\n')\n",
    "print('done 2/2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
